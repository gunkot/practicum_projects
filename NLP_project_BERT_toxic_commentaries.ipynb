{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01753bca",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a4869",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Нужно построить модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. \n",
    "\n",
    "Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ab2fb",
   "metadata": {},
   "source": [
    "## Подготовка BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a42462",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\easym\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\easym\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.1 tokenizers-0.13.2 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ca7309",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-1.1.1-cp39-none-win_amd64.whl (74.0 MB)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\easym\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.1.1 graphviz-0.20.1\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\easym\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\easym\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\easym\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\easym\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b12d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6833327e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# загрузим датасет\n",
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv('datasets/toxic_comments.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532c921e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab92d31b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проценты классов:\n",
      "0    89.84\n",
      "1    10.16\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = round((data['toxic'].value_counts() / data.shape[0]) * 100, 2)\n",
    "print('Проценты классов:')\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar', legend=True, figsize=(3,2), grid=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d039eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data.sample(10000)\n",
    "data_sample, _ = train_test_split(data,\n",
    "                                  train_size=4000/data.shape[0], \n",
    "                                  random_state=12345,\n",
    "                                  stratify=data['toxic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec9237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент от исходного датасета: 2.51%,\n",
      "Размер выборки: (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Процент от исходного датасета: {(data_sample.shape[0] / data.shape[0]):.2%},\\nРазмер выборки: {data_sample.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "438560a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проценты классов:\n",
      "0    89.85\n",
      "1    10.15\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = round((data_sample['toxic'].value_counts() / data_sample.shape[0]) * 100, 2)\n",
    "print('Проценты классов:')\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar', legend=True, figsize=(3,2), grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f455c6",
   "metadata": {},
   "source": [
    "Наблюдения:\n",
    "- Есть столбец `Unnamed: 0` - видимо, бывшие индексы. Его можно просто удалить.\n",
    "- Столбец `toxic` - целевой признак, содержит два класса: `0` - не токсичный комментарий, `1` - токсичный. Заметен сильный дисбаланс классов, токсичных всего 10% всего датасета.\n",
    "- Столбец `data['text']` - содержит фразы на английском. Следовательно нужен BERT для английского языка. \n",
    "    - Так как BERT очень тяжелый, возьмем семпл 10 тысяч объектов. Проверили, сохраняется ли на этой выборке дисбаланс. 9,96% - примерно так же, как и в всем датасете.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c690253",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a363f6c7a2e74b3ca71f61637a31a35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50897a00ac9c474f92b5099cff5ab8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55956debe5f443bcaea0ed295a2a6a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bb9be07882498d8440418d48b52760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0ca67165e040c69aaa1dcf1c118852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/bert-base-cased-conversational\")\n",
    "#model = AutoModel.from_pretrained(\"DeepPavlov/bert-base-cased-conversational\")\n",
    "\n",
    "model = transformers.AutoModel.from_pretrained('unitary/toxic-bert')\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ff768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = data_sample['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc66264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc6972fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e84a8",
   "metadata": {},
   "source": [
    "Специально пришлось обрезать длину векторов\n",
    "truncation=True, max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49512f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a879849990443b189a0fc7f48a1bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 10min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd6239a",
   "metadata": {},
   "source": [
    "За 3,5 часа у меня посчиталось 6,3% всего датасета :)))\n",
    "\n",
    "UPD: toxic-bert 1ч10мин на 2.51% датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2699bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76c6c0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddf14edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраню на всякий случай фичи\n",
    "df_bert_features = pd.DataFrame(bert_features, index=data_sample.index)\n",
    "df_bert_features['toxic'] = data_sample['toxic']\n",
    "df_bert_features.to_csv(\"datasets/toxic_bert_features_target.csv\",index=False)\n",
    "#df_bert_features.to_csv(\"datasets/bert_features_target.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32581f1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133007</th>\n",
       "      <td>-0.409640</td>\n",
       "      <td>-0.682354</td>\n",
       "      <td>0.694877</td>\n",
       "      <td>-0.387380</td>\n",
       "      <td>1.116177</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>0.638707</td>\n",
       "      <td>0.035917</td>\n",
       "      <td>-0.429374</td>\n",
       "      <td>-0.693715</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092966</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>-0.651163</td>\n",
       "      <td>-0.013004</td>\n",
       "      <td>0.653972</td>\n",
       "      <td>-0.355653</td>\n",
       "      <td>-0.611036</td>\n",
       "      <td>0.687749</td>\n",
       "      <td>0.381993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>-0.858708</td>\n",
       "      <td>-1.081910</td>\n",
       "      <td>0.246214</td>\n",
       "      <td>-0.550063</td>\n",
       "      <td>1.226489</td>\n",
       "      <td>0.493677</td>\n",
       "      <td>-0.063121</td>\n",
       "      <td>-0.145448</td>\n",
       "      <td>-0.379268</td>\n",
       "      <td>-0.509379</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.157018</td>\n",
       "      <td>0.249814</td>\n",
       "      <td>-0.680220</td>\n",
       "      <td>0.068209</td>\n",
       "      <td>0.829675</td>\n",
       "      <td>-0.421107</td>\n",
       "      <td>-0.830782</td>\n",
       "      <td>0.453771</td>\n",
       "      <td>-0.038509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>-0.673145</td>\n",
       "      <td>-0.880663</td>\n",
       "      <td>0.753622</td>\n",
       "      <td>-0.465708</td>\n",
       "      <td>1.274365</td>\n",
       "      <td>0.298940</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.297773</td>\n",
       "      <td>-0.453670</td>\n",
       "      <td>-0.673237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946159</td>\n",
       "      <td>0.303214</td>\n",
       "      <td>-0.681259</td>\n",
       "      <td>0.174515</td>\n",
       "      <td>0.657640</td>\n",
       "      <td>-0.611828</td>\n",
       "      <td>-0.646030</td>\n",
       "      <td>0.652186</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81809</th>\n",
       "      <td>-0.635174</td>\n",
       "      <td>-0.989515</td>\n",
       "      <td>0.437669</td>\n",
       "      <td>-0.366011</td>\n",
       "      <td>1.064908</td>\n",
       "      <td>0.238560</td>\n",
       "      <td>-0.169302</td>\n",
       "      <td>0.040857</td>\n",
       "      <td>-0.451379</td>\n",
       "      <td>-0.645360</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245401</td>\n",
       "      <td>0.122063</td>\n",
       "      <td>-0.707842</td>\n",
       "      <td>0.221734</td>\n",
       "      <td>0.997048</td>\n",
       "      <td>-0.613303</td>\n",
       "      <td>-0.706120</td>\n",
       "      <td>0.391476</td>\n",
       "      <td>0.117196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58025</th>\n",
       "      <td>-0.568447</td>\n",
       "      <td>-0.787825</td>\n",
       "      <td>0.586156</td>\n",
       "      <td>-0.601193</td>\n",
       "      <td>1.032078</td>\n",
       "      <td>0.429114</td>\n",
       "      <td>0.234472</td>\n",
       "      <td>-0.090180</td>\n",
       "      <td>-0.343484</td>\n",
       "      <td>-0.768675</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.131095</td>\n",
       "      <td>0.603504</td>\n",
       "      <td>-0.550489</td>\n",
       "      <td>0.122606</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>-0.572755</td>\n",
       "      <td>-0.675945</td>\n",
       "      <td>0.646105</td>\n",
       "      <td>0.237480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "133007 -0.409640 -0.682354  0.694877 -0.387380  1.116177  0.367554  0.638707   \n",
       "3710   -0.858708 -1.081910  0.246214 -0.550063  1.226489  0.493677 -0.063121   \n",
       "8981   -0.673145 -0.880663  0.753622 -0.465708  1.274365  0.298940  0.004354   \n",
       "81809  -0.635174 -0.989515  0.437669 -0.366011  1.064908  0.238560 -0.169302   \n",
       "58025  -0.568447 -0.787825  0.586156 -0.601193  1.032078  0.429114  0.234472   \n",
       "\n",
       "               7         8         9  ...       759       760       761  \\\n",
       "133007  0.035917 -0.429374 -0.693715  ... -1.092966  0.370968 -0.651163   \n",
       "3710   -0.145448 -0.379268 -0.509379  ... -1.157018  0.249814 -0.680220   \n",
       "8981    0.297773 -0.453670 -0.673237  ... -0.946159  0.303214 -0.681259   \n",
       "81809   0.040857 -0.451379 -0.645360  ... -1.245401  0.122063 -0.707842   \n",
       "58025  -0.090180 -0.343484 -0.768675  ... -1.131095  0.603504 -0.550489   \n",
       "\n",
       "             762       763       764       765       766       767  toxic  \n",
       "133007 -0.013004  0.653972 -0.355653 -0.611036  0.687749  0.381993      0  \n",
       "3710    0.068209  0.829675 -0.421107 -0.830782  0.453771 -0.038509      0  \n",
       "8981    0.174515  0.657640 -0.611828 -0.646030  0.652186  0.425806      0  \n",
       "81809   0.221734  0.997048 -0.613303 -0.706120  0.391476  0.117196      0  \n",
       "58025   0.122606  0.531818 -0.572755 -0.675945  0.646105  0.237480      0  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "869de8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если при перезапуске ядра все потерялось\n",
    "#df_bert_features = pd.read_csv('datasets/bert_features_target.csv')\n",
    "df_bert_features = pd.read_csv('datasets/toxic_bert_features_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03804bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_features = df_bert_features.drop('toxic', axis=1)\n",
    "bert_target = df_bert_features['toxic']\n",
    "bert_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de126847",
   "metadata": {},
   "source": [
    "## Обучение BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adf05e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы обучающей выборки: (3000, 768)\n",
      "Размер матрицы тестовой выборки: (1000, 768)\n"
     ]
    }
   ],
   "source": [
    "bert_features_train, bert_features_test, bert_target_train, bert_target_test = train_test_split(bert_features, \n",
    "                                                                                                bert_target, \n",
    "                                                                                                test_size=0.25,\n",
    "                                                                                                random_state=12345)\n",
    "\n",
    "print(\"Размер матрицы обучающей выборки:\", bert_features_train.shape)\n",
    "print(\"Размер матрицы тестовой выборки:\", bert_features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733086e4",
   "metadata": {},
   "source": [
    "В случае использования эмбедингов от Берта, никакой утечки данных нет. Поэтому проще сделать преобразование (векторизацию) на всём датасете, а потом разделить на выборки - меньше кода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322ce4f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f35abe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающей выборке: 0.9392318546719358\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression без взвешивания\n",
    "bert_model = LogisticRegression(random_state=12345, max_iter=1000) #, class_weight='balanced'\n",
    "bert_model.fit(bert_features_train, bert_target_train) \n",
    "\n",
    "print(f'F1 на обучающей выборке:', cross_val_score(bert_model, \n",
    "                                                    bert_features_train, \n",
    "                                                    bert_target_train, \n",
    "                                                    cv = 4, \n",
    "                                                    n_jobs = -1, \n",
    "                                                    scoring = 'f1').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dd97a88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogistic Regression BERT (GridSearchCV)\n",
      "Fitting 4 folds for each of 80 candidates, totalling 320 fits\n",
      "F1 на обучающей выборке: 0.9392318546719358\n",
      "Гиперараметры: {'C': 0.9000000000000001, 'class_weight': None, 'max_iter': 100}\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic Regression. Подбор параметров\n",
    "print('\\tLogistic Regression BERT (GridSearchCV)')\n",
    "bert_model_logreg = LogisticRegression(random_state=12345)\n",
    "\n",
    "parameters = {'max_iter': [100, 500, 1000, 2000],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'C': np.arange(0.1, 2.0, 0.2)\n",
    "              #'solver': ['lbfgs', 'liblinear', 'newton-cholesky', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "bert_grid_logreg = GridSearchCV(bert_model_logreg, parameters, cv=3, verbose=3, n_jobs=-1, scoring = 'f1')\n",
    "bert_grid_logreg.fit(bert_features_train, bert_target_train)\n",
    "\n",
    "print(f'F1 на обучающей выборке: {abs(bert_grid_logreg.best_score_)}')\n",
    "\n",
    "print('Гиперараметры:', bert_grid_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c04bea",
   "metadata": {},
   "source": [
    "__Logistic Regression__\n",
    "\n",
    "Как было до этого с `bert-base-cased-conversational`:\n",
    "- `{'C': 0.3, 'class_weight': None, 'max_iter': 100}`\n",
    "- `F1` на обучающей выборке: `0.66253`\n",
    "- Время: прим. 5 мин\n",
    "\n",
    "Как стало с `toxic-bert`:\n",
    "- `{'C': 0.9, 'class_weight': None, 'max_iter': 100}`\n",
    "- `F1` на обучающей выборке: `0.93923`\n",
    "- Время: Wall time: 1min 29s\n",
    "\n",
    "Стало быстрее и гораздо точнее. Метрика F1 улучшилась. \n",
    "\n",
    "Вывод: правильный подбор предобученной модели Bert существенно влияет на качество."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14ba29",
   "metadata": {},
   "source": [
    "### LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "060d21af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLight GBM Classifier BERT (GridSearchCV)\n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "F1 на обучающей выборке: 0.9356526405222914\n",
      "Гиперараметры: {'class_weight': 'balanced', 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 10}\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LightGBM. Подбор параметров\n",
    "print('\\tLight GBM Classifier BERT (GridSearchCV)')\n",
    "bert_model_lgbm = LGBMClassifier(random_state=12345)\n",
    "\n",
    "parameters = {'max_depth': [-1, 2, 3, 5], \n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'n_estimators': [50, 100, 150, 300], #50\n",
    "              #'learning_rate': [0.1, 0.01]\n",
    "              'num_leaves':[10, 30, 50]\n",
    "             }\n",
    "\n",
    "bert_grid_lgbm = GridSearchCV(bert_model_lgbm, parameters, cv=3, verbose=3, n_jobs=-1, scoring = 'f1')\n",
    "bert_grid_lgbm.fit(bert_features_train, bert_target_train)\n",
    "\n",
    "print(f'F1 на обучающей выборке: {abs(bert_grid_lgbm.best_score_)}')\n",
    "print('Гиперараметры:', bert_grid_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85b7f6",
   "metadata": {},
   "source": [
    "__LightGBM__\n",
    "\n",
    "Как было до этого с `bert-base-cased-conversational`:\n",
    "- `{'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 100}`\n",
    "- `F1` на обучающей выборке: `0.63551`\n",
    "- Время: Wall time: 2min 44s\n",
    "\n",
    "Как стало с `toxic-bert`:\n",
    "- `{'class_weight': None, 'max_depth': 2, 'n_estimators': 100}`\n",
    "- `F1` на обучающей выборке: `0.93111`\n",
    "- Время: Wall time:  1min 25s\n",
    "\n",
    "Снова стало быстрее и точнее, но не настолько точно, как у ЛогРег.\n",
    "\n",
    "Подберем побольше параметров.\n",
    "- `'class_weight': 'balanced', 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 10`\n",
    "- `F1` на обучающей выборке: `0.93565`\n",
    "- Wall time: 4min 32s\n",
    "\n",
    "Стало еще лучше, но до ЛогРега все равно не хватает 4 тысячных доли."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a956701",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35da0517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandomForest Classifier BERT (GridSearchCV)\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "F1 на обучающей выборке: 0.9378437505650075\n",
      "Гиперараметры: {'class_weight': None, 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 60}\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RandomForest Classifier. Подбор параметров\n",
    "print('\\tRandomForest Classifier BERT (GridSearchCV)')\n",
    "bert_model_forest = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "parameters = {'max_depth': [None, 3, 5, 50], \n",
    "              'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "              'n_estimators': [50, 60, 100, 300],\n",
    "              'min_samples_split': [2, 3, 5]\n",
    "              #'min_samples_leaf': [1, 3, 5]\n",
    "             }\n",
    "\n",
    "bert_grid_forest = GridSearchCV(bert_model_forest, parameters, cv=3, verbose=3, n_jobs=-1, scoring = 'f1')\n",
    "bert_grid_forest.fit(bert_features_train, bert_target_train)\n",
    "\n",
    "print(f'F1 на обучающей выборке: {abs(bert_grid_forest.best_score_)}')\n",
    "print('Гиперараметры:', bert_grid_forest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a086b",
   "metadata": {},
   "source": [
    "__RandomForest__\n",
    "\n",
    "Как было до этого с `bert-base-cased-conversational`:\n",
    "- `'class_weight': None, 'max_depth': None, 'n_estimators': 300\t`\n",
    "- `F1` на обучающей выборке: `0.3822`\n",
    "- Время: Wall time: 2min 45s\n",
    "\n",
    "Как стало с `toxic-bert`:\n",
    "- `'class_weight': None, 'max_depth': None, 'n_estimators': 50`\n",
    "- `F1` на обучающей выборке: `0.93622`\n",
    "- Время: Wall time: 42s\n",
    "\n",
    "Опять быстрее и точнее, лучше, чем LightGBM, но все еще чуть хуже ЛогРег.\n",
    "\n",
    "Подберем побольше параметров.\n",
    "\n",
    "- `'class_weight': None, 'max_depth': None, 'n_estimators': 60`\n",
    "- `F1` на обучающей выборке: `0.93767`\n",
    "- Время: Wall time: 50.6 s\n",
    "\n",
    "№2\n",
    "\n",
    "- `'class_weight': None, 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 60`\n",
    "- `F1` на обучающей выборке: `0.93784`\n",
    "- Время: Wall time: 2min 6s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cf3e4",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a7e38",
   "metadata": {},
   "source": [
    "Сводка по моделям (__при использовании BERT-base-cased-conversational__, выборка 10000 объектов) на обучающей выборке:\n",
    "\n",
    "| Модель   | Гиперпараметры                                                 | Точность результата (F1 score) | \n",
    "|:----------------------------:|:--------------------------------------------------------------:|:------------------------------:|\n",
    "| Логистическая регрессия      | `'class_weight': None, 'C': 0.3, 'max_iter': 100`              | 0.6625              | \n",
    "| Light GBM                    | `'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 100` | 0.6355           |\n",
    "| Random Forest                | `'class_weight': None, 'max_depth': None, 'n_estimators': 300`    | 0.3822           |\n",
    "\n",
    "\n",
    "Сводка по моделям (__`при использовании toxic-BERT`__, выборка 4000 объектов) на обучающей выборке, внимание на точность:\n",
    "\n",
    "| Модель                       | Гиперпараметры                                                 | Точность результата (F1 score) | \n",
    "|:----------------------------:|:--------------------------------------------------------------:|:------------------------------:|\n",
    "| Логистическая регрессия      | `'C': 0.9, 'class_weight': None, 'max_iter': 100`              | 0.93923             | \n",
    "| Light GBM                    | `'class_weight': 'balanced', 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 10` | 0.93565         |\n",
    "| Random Forest                | `'class_weight': None, 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 60`    | 0.93784          |\n",
    "\n",
    "Лучше всего показала себя __логистическая регрессия__, как по точности, так и по времени подбора параметров. \n",
    "\n",
    "Возможно, если лучше подбирать параметры для леса и градиентного бустинга, то они тоже покажут лучше результаты. \n",
    "\n",
    "_Также, важна модель BERT - правильно подобранная модель под задачу сильно влияет на точность предсказаний._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "429fc6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке:  0.9206349206349206\n"
     ]
    }
   ],
   "source": [
    "# тестовая выборка\n",
    "bert_predictions_test = bert_grid_logreg.predict(bert_features_test)\n",
    "print(f'F1 на тестовой выборке: ', f1_score(bert_target_test, bert_predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad352a",
   "metadata": {},
   "source": [
    "На тестовой выборке логистическая регрессия показала себя так же хорошо: результат по ___f1 метрике равен `0.92`___.\n",
    "\n",
    "А при использовании BERT-base-cased-conversational, на тестовой выборке метрика f1 была равна 0.7011. Разница на лицо.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a9df9",
   "metadata": {},
   "source": [
    "- _Почему была выбрана метрика f1?_\n",
    "\n",
    "    Предполагаю, что метрика F1 выбрана, потому что есть дисбаланс классов, и она показывает общее среднее между точностью (precision) и полнотой (recall). То есть мы стремимся сразу и к более точному предсказанию токсического комментария, и одновременно нам нужно угадать их как можно больше. То есть стремимся к балансу. Можно сказать, что в этой задаче accuracy бессмысленна, так как сильный дисбаланс. Но почему не AUC-ROC, тут сложно. Можно предположить, что в F1 метрике важны точность и полнота угадывания одного класса с учетом дисбаланса, а в AUC-ROC важны полнота угадывания положительного класса и полнота угадывания отрицательного класса бинарной классификации - и их гармония.\n",
    "    \n",
    "    \n",
    "- _Что если бы нам было нужно найти как можно больше токсичных комментариев, в этом случаи на какую метрику мы бы ориентировались?_\n",
    "\n",
    "    Полнота (recall) - так как именно она увеличивается, когда доля правильно предсказанных объекто класса \"1\" действительно подходит к доле всех объектов класса \"1\" на датасете. То есть как можно больше угадать токсичных комментариев из всех.\n",
    "    \n",
    "    \n",
    "- _Каким образом мы можем изменить функцию ошибки в модели, чтобы она максимизировала интересующую нас метрику (accuracy, f1, precision, roc-auc и т.п.)?_\n",
    "\n",
    "    Мы никак не можем изменить функцию ошибки, чтобы в процессе обучения, двигаясь по антиградиенту, минимизировались какие то конкретные метрики качества (precision или recall или roc-auc - нет у них производной)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d68f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
